# -*- coding: utf-8 -*-
"""handwriting_EAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hSpRLD57b9YMdmPxVhEtdfrxKH89uZlI
"""

from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, models
from tensorflow.keras.layers.experimental import preprocessing


# Data Augmentation layers
data_augmentation = tf.keras.Sequential([
    RandomFlip("horizontal"),
    RandomRotation(0.2),
    RandomZoom(0.2),
])

# Load training and validation datasets with data augmentation
train_ds = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/spiral_dataset/train',
    image_size=(256, 256),
    batch_size=32,
    shuffle=True,
)
train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))

validation_ds = tf.keras.utils.image_dataset_from_directory(
    '/content/drive/MyDrive/spiral_dataset/test',
    image_size=(256, 256),
    batch_size=32,
)

# Load pre-trained ResNet50 model without top (fully connected layers)
resnet_model = ResNet50(weights='imagenet', include_top=False)

# Define additional layers
flatten_layer = layers.Flatten()
dense_layer1 = layers.Dense(128, activation='relu')
output_layer = layers.Dense(1, activation='sigmoid')

# Build the CNN model with ResNet50 as the base
inputs = layers.Input(shape=(256, 256, 3))
x = data_augmentation(inputs)  # Apply data augmentation
x = resnet_model(x)
x = flatten_layer(x)
x = dense_layer1(x)
outputs = output_layer(x)
model = models.Model(inputs=inputs, outputs=outputs)

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Early stopping callback
early_stopping = EarlyStopping(patience=3, restore_best_weights=True)

# Train the model and collect history
history = model.fit(train_ds, epochs=10, validation_data=validation_ds, callbacks=[early_stopping])

from google.colab import drive
drive.mount('/content/drive')

IMAGE_SIZE = [224, 224]
vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)
#here [3] denotes for RGB images(3 channels)

#don't train existing weights
for layer in vgg.layers:
 layer.trainable = False

x = Flatten()(vgg.output)
prediction = Dense(2, activation='sigmoid')(x)
model = Model(inputs=vgg.input, outputs=prediction)
model.compile(loss='binary_crossentropy',
                    optimizer=optimizers.Adam(),
                    metrics=['accuracy'])
model.summary()

pip install lime

import lime
from lime import lime_image

# Initialize Lime explainer
explainer = lime_image.LimeImageExplainer()

# Explain the model's prediction for the sample image
explanation = explainer.explain_instance(img_array[0].astype('double'), model.predict, top_labels=1, hide_color=0, num_samples=1000)

# Show the explanation
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
# plt.imshow(lime.mark_boundaries(temp / 2 + 0.5, mask))
# plt.show()

plt.imshow(explanation.image)
plt.show()